{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Kaggle Titanic Baseline\\n",
        "\\n",
        "This notebook mirrors the baseline pipeline in `src/train.py` and produces a `submission.csv` file for the Kaggle Titanic competition.\\n",
        "\\n",
        "**Before you start:** place `train.csv` and `test.csv` inside the `data/` directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_dir = Path(\"data\")\n",
        "train_path = data_dir / \"train.csv\"\n",
        "test_path = data_dir / \"test.csv\"\n",
        "\n",
        "if not train_path.exists():\n",
        "    raise FileNotFoundError(\"Missing data/train.csv. Download it from Kaggle.\")\n",
        "if not test_path.exists():\n",
        "    raise FileNotFoundError(\"Missing data/test.csv. Download it from Kaggle.\")\n",
        "\n",
        "train_df = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build the preprocessing + model pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_cols = [\n",
        "    \"Pclass\",\n",
        "    \"Sex\",\n",
        "    \"Age\",\n",
        "    \"SibSp\",\n",
        "    \"Parch\",\n",
        "    \"Fare\",\n",
        "    \"Embarked\",\n",
        "]\n",
        "\n",
        "numeric_features = [\"Pclass\", \"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
        "categorical_features = [\"Sex\", \"Embarked\"]\n",
        "\n",
        "numeric_transformer = Pipeline(\n",
        "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\"))]\n",
        ")\n",
        "\n",
        "categorical_transformer = Pipeline(\n",
        "    steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
        "    ]\n",
        ")\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, numeric_features),\n",
        "        (\"cat\", categorical_transformer, categorical_features),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "pipeline = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocessor\", preprocessor),\n",
        "        (\"model\", model),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train = train_df[feature_cols]\n",
        "y_train = train_df[\"Survived\"]\n",
        "x_test = test_df[feature_cols]\n",
        "\n",
        "pipeline.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate a submission file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = pipeline.predict(x_test)\n",
        "\n",
        "submission = pd.DataFrame(\n",
        "    {\"PassengerId\": test_df[\"PassengerId\"], \"Survived\": predictions}\n",
        ")\n",
        "\n",
        "output_dir = Path(\"output\")\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "output_path = output_dir / \"submission.csv\"\n",
        "submission.to_csv(output_path, index=False)\n",
        "\n",
        "output_path"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
